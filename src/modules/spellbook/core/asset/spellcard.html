<p class="mb-4">
  <b style="font-size: 0.8rem; color: red">
    Requirements: ExLlama is required for routing to work. For a real-time
    experience, a 30X0 or better is needed.</b
  >
  <br /><br />
  The AI assistant application leverages large language models like Llama to
  engage in dynamic and contextually rich conversations. Users can ask
  questions, seek information, or request the model to perform text-based tasks
  such as writing, editing, or brainstorming ideas. The model can comprehend the
  input query and generate responses in natural language, making the interaction
  smooth and user-friendly. In addition to accessing LLMs, the primary advantage
  of using Spell Book over a vanilla LLM chat client is its function calling and
  model routing abilities. To take advantage of these, two models are required
  to be running: <b style="color: blue">Llama 7B (ExLlama)</b> and
  <b style="color: blue">T5 Large v2</b>. These two models are used in
  conjunction with two Loras to provide the function calling services for Spell
  Book. To start these models, go to the <a href="/#/servers">Servers</a> tab
  and follow these directions. <br /><br />

  See
  <a
    href="https://github.com/noco-ai/spellbook-docker/wiki/Getting-started-with-Chat-Abilities"
    >Getting started with Chat Abilities</a
  >
  for instructions on installing and running the models needed for chat
  abilities to function.
</p>
